{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da419be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets,transforms\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fef36db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b2ea7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), transforms.Grayscale()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4928644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "/Users/sreesai/Learning/DeepLearning/.venv/lib/python3.14/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  entry = pickle.load(f, encoding=\"latin1\")\n"
     ]
    }
   ],
   "source": [
    "train_set = datasets.CIFAR10(\n",
    "    root=\"./data/CIFAR10\",\n",
    "    train = True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_set = datasets.CIFAR10(\n",
    "    root=\"./data/CIFAR10\",\n",
    "    train = False,\n",
    "    transform = transform,\n",
    "    download = True\n",
    ")\n",
    "\n",
    "train_size = int(len(train_set)*0.9)\n",
    "val_size = len(train_set)-train_size\n",
    "train_set,val_set = torch.utils.data.random_split(train_set,[train_size,val_size])\n",
    "\n",
    "batch_size=128\n",
    "\n",
    "train_loader = DataLoader(train_set,batch_size,True)\n",
    "val_loader = DataLoader(val_set,batch_size,True)\n",
    "test_loader = DataLoader(test_set,batch_size,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80146d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.2277, 0.2528, 0.2821,  ..., 0.2639, 0.2382, 0.1932],\n",
       "          [0.4346, 0.4049, 0.3482,  ..., 0.2896, 0.2460, 0.2070],\n",
       "          [0.3000, 0.2396, 0.1854,  ..., 0.3463, 0.3320, 0.2902],\n",
       "          ...,\n",
       "          [0.0591, 0.0441, 0.0437,  ..., 0.3356, 0.2709, 0.2591],\n",
       "          [0.0450, 0.0594, 0.0423,  ..., 0.3455, 0.2710, 0.2234],\n",
       "          [0.1256, 0.1155, 0.0857,  ..., 0.2500, 0.2108, 0.2373]]]),\n",
       " 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0758937",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,64,kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(64,128,kernel_size=3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(128,128,kernel_size=3,padding=1)\n",
    "        self.conv5 = nn.Conv2d(128,128,kernel_size=3,padding=1)\n",
    "        self.conv6 = nn.Conv2d(128,128,kernel_size=3,padding=1)\n",
    "        self.maxp = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(128,64)\n",
    "        self.fc2 = nn.Linear(64,10)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.maxp(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.maxp(x)\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.maxp(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75ad0366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs,labels)\n",
    "\n",
    "            running_loss += loss.item()*images.size(0)\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds==labels).sum().item()\n",
    "    val_loss = running_loss / len(loader.dataset)\n",
    "    accuracy = correct/len(loader.dataset)\n",
    "\n",
    "    return val_loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12803733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model,optimizer,criterion,loader,device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images,labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs=model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()*images.size(0)\n",
    "    epoch_loss = running_loss/len(loader.dataset)\n",
    "    return epoch_loss       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1fabbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "simple_cnn(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "model = simple_cnn().to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr = 1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26a1a778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] Train Loss: 1.2678 Val Loss: 1.0783 Val Acc: 0.6148\n",
      "Epoch [2/15] Train Loss: 0.8329 Val Loss: 0.9744 Val Acc: 0.6662\n",
      "Epoch [3/15] Train Loss: 0.6580 Val Loss: 0.8315 Val Acc: 0.7258\n",
      "Epoch [4/15] Train Loss: 0.5421 Val Loss: 0.8076 Val Acc: 0.7322\n",
      "Epoch [5/15] Train Loss: 0.4555 Val Loss: 0.7525 Val Acc: 0.7498\n",
      "Epoch [6/15] Train Loss: 0.3882 Val Loss: 0.6960 Val Acc: 0.7704\n",
      "Epoch [7/15] Train Loss: 0.3259 Val Loss: 1.2030 Val Acc: 0.6854\n",
      "Epoch [8/15] Train Loss: 0.2692 Val Loss: 0.7899 Val Acc: 0.7574\n",
      "Epoch [9/15] Train Loss: 0.2174 Val Loss: 0.6728 Val Acc: 0.7920\n",
      "Epoch [10/15] Train Loss: 0.1772 Val Loss: 0.7206 Val Acc: 0.7906\n",
      "Epoch [11/15] Train Loss: 0.1378 Val Loss: 1.2142 Val Acc: 0.7264\n",
      "Epoch [12/15] Train Loss: 0.1170 Val Loss: 0.7414 Val Acc: 0.8008\n",
      "Epoch [13/15] Train Loss: 0.0957 Val Loss: 0.9191 Val Acc: 0.7814\n",
      "Epoch [14/15] Train Loss: 0.0806 Val Loss: 0.9143 Val Acc: 0.7898\n",
      "Epoch [15/15] Train Loss: 0.0738 Val Loss: 0.9228 Val Acc: 0.7910\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(\n",
    "        model=model,loader=train_loader,\n",
    "        optimizer=optimizer,criterion=criterion,\n",
    "        device=device\n",
    "    )\n",
    "    val_loss,val_acc = evaluate(\n",
    "        model,val_loader, criterion,device\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "        f\"Train Loss: {train_loss:.4f} \"\n",
    "        f\"Val Loss: {val_loss:.4f} \"\n",
    "        f\"Val Acc: {val_acc:.4f}\"\n",
    "    )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5921fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
